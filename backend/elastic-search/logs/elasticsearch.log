[2017-11-26T12:28:20,511][INFO ][o.e.n.Node               ] [] initializing ...
[2017-11-26T12:28:20,614][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] using [1] data paths, mounts [[/ (/dev/disk1s1)]], net usable_space [11.4gb], net total_space [233.5gb], spins? [unknown], types [apfs]
[2017-11-26T12:28:20,614][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] heap size [1.7gb], compressed ordinary object pointers [true]
[2017-11-26T12:28:20,658][INFO ][o.e.n.Node               ] node name [WuuaeiX] derived from node ID [WuuaeiX1RimIKqB0gbnf_A]; set [node.name] to override
[2017-11-26T12:28:20,662][INFO ][o.e.n.Node               ] version[5.6.3], pid[3283], build[1a2f265/2017-10-06T20:33:39.012Z], OS[Mac OS X/10.13.1/x86_64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_112/25.112-b16]
[2017-11-26T12:28:20,662][INFO ][o.e.n.Node               ] JVM arguments [-Des.path.home=/Users/Guida/GitHub/lime/backend/elastic-search]
[2017-11-26T12:28:22,297][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [aggs-matrix-stats]
[2017-11-26T12:28:22,299][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [ingest-common]
[2017-11-26T12:28:22,300][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-expression]
[2017-11-26T12:28:22,300][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-groovy]
[2017-11-26T12:28:22,300][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-mustache]
[2017-11-26T12:28:22,300][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-painless]
[2017-11-26T12:28:22,300][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [parent-join]
[2017-11-26T12:28:22,301][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [percolator]
[2017-11-26T12:28:22,301][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [reindex]
[2017-11-26T12:28:22,301][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty3]
[2017-11-26T12:28:22,301][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty4]
[2017-11-26T12:28:22,302][INFO ][o.e.p.PluginsService     ] [WuuaeiX] no plugins loaded
[2017-11-26T12:28:24,886][INFO ][o.e.d.DiscoveryModule    ] [WuuaeiX] using discovery type [zen]
[2017-11-26T12:28:26,040][INFO ][o.e.n.Node               ] initialized
[2017-11-26T12:28:26,040][INFO ][o.e.n.Node               ] [WuuaeiX] starting ...
[2017-11-26T12:28:26,109][INFO ][i.n.u.i.PlatformDependent] Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system instability.
[2017-11-26T12:28:26,337][INFO ][o.e.t.TransportService   ] [WuuaeiX] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2017-11-26T12:28:26,354][WARN ][o.e.b.BootstrapChecks    ] [WuuaeiX] initial heap size [134217728] not equal to maximum heap size [2147483648]; this can cause resize pauses and prevents mlockall from locking the entire heap
[2017-11-26T12:28:29,424][INFO ][o.e.c.s.ClusterService   ] [WuuaeiX] new_master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2017-11-26T12:28:29,466][INFO ][o.e.h.n.Netty4HttpServerTransport] [WuuaeiX] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2017-11-26T12:28:29,467][INFO ][o.e.n.Node               ] [WuuaeiX] started
[2017-11-26T12:28:29,743][INFO ][o.e.g.GatewayService     ] [WuuaeiX] recovered [2] indices into cluster_state
[2017-11-26T12:28:30,787][INFO ][o.e.c.r.a.AllocationService] [WuuaeiX] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[twitter][1]] ...]).
[2017-11-26T12:28:51,203][INFO ][o.e.c.m.MetaDataMappingService] [WuuaeiX] [locations/IpS3Yru_RjysBsird7c0hw] update_mapping [loc]
[2017-11-26T12:28:57,554][INFO ][o.e.m.j.JvmGcMonitorService] [WuuaeiX] [gc][31] overhead, spent [566ms] collecting in the last [1.4s]
[2017-11-26T12:28:59,469][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:28:59,470][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:29:29,497][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:29:59,536][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:29:59,536][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:30:29,560][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:30:59,596][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:30:59,597][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:31:29,620][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:31:59,655][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:31:59,655][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:32:29,675][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:32:59,696][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:32:59,696][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:33:29,722][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:33:59,756][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:33:59,757][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:34:29,786][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:34:59,811][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:34:59,812][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:35:29,837][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:35:59,861][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:35:59,861][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:36:29,891][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:36:59,925][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:36:59,926][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:37:29,957][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:38:00,011][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:38:00,011][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:38:30,041][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:39:00,068][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:39:00,069][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:39:30,094][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:40:00,114][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T12:40:00,115][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:40:30,163][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:41:00,185][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:41:00,186][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:41:30,281][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:42:00,303][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:42:00,304][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:42:30,323][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:43:00,343][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:43:00,343][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:43:30,368][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:44:00,389][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:44:00,389][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:44:30,415][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:45:00,436][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:45:00,436][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:45:30,459][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:46:00,484][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:46:00,484][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:46:30,513][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:47:00,567][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:47:00,567][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:47:30,640][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:48:00,684][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:48:00,685][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:48:30,712][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:49:00,734][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:49:00,734][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:49:30,756][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:50:00,777][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:50:00,777][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:50:30,811][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:51:00,852][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:51:00,852][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:51:30,906][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:52:00,945][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:52:00,945][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:52:30,986][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:53:01,016][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:53:01,016][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:53:31,055][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:54:01,099][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:54:01,099][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:54:31,129][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:55:01,162][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:55:01,162][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:55:31,216][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:56:01,311][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:56:01,311][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:56:31,356][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:57:01,386][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:57:01,386][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:57:31,421][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:58:01,455][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:58:01,455][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:58:31,490][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:59:01,520][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:59:01,520][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T12:59:31,552][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T12:59:58,506][INFO ][o.e.c.m.MetaDataDeleteIndexService] [WuuaeiX] [locations/IpS3Yru_RjysBsird7c0hw] deleting index
[2017-11-26T13:00:01,558][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:00:01,574][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T13:00:09,443][INFO ][o.e.c.m.MetaDataDeleteIndexService] [WuuaeiX] [twitter/nLUnTJ2iROm2NvSNQer9AQ] deleting index
[2017-11-26T13:00:31,581][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:01:01,588][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:01:01,588][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T13:01:31,593][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:13:00,078][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:13:00,078][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T13:13:30,091][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:14:00,396][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:14:00,396][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T13:14:30,403][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:16:35,937][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T13:16:35,937][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T13:17:05,947][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T15:24:21,212][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T15:24:21,213][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T15:24:51,220][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T15:25:21,231][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T15:25:21,232][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T15:32:29,613][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T15:32:59,622][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T15:32:59,622][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T15:41:15,133][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T15:41:45,145][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T15:41:45,145][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T15:51:21,791][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T15:51:51,801][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T15:51:51,801][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:02:09,372][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:02:39,379][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.1gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:02:39,379][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:03:09,386][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:03:39,393][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:03:39,393][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:04:09,396][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:04:39,402][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:04:39,402][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:05:09,407][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:05:39,413][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:05:39,414][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:06:09,419][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:06:17,729][INFO ][o.e.c.m.MetaDataCreateIndexService] [WuuaeiX] [locations] creating index, cause [auto(update api)], templates [], shards [5]/[1], mappings []
[2017-11-26T16:06:17,942][INFO ][o.e.c.m.MetaDataMappingService] [WuuaeiX] [locations/C_vQZz9gTLa6yUoQKxJxKw] create_mapping [loc]
[2017-11-26T16:06:28,532][WARN ][o.e.t.n.Netty4Transport  ] [WuuaeiX] write and flush on the network layer failed (channel: [id: 0x464c5380, L:0.0.0.0/0.0.0.0:9300 ! R:/127.0.0.1:53604])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[?:?]
[2017-11-26T16:06:28,488][WARN ][i.n.c.DefaultChannelPipeline] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) ~[?:?]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:110) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_112]
	at io.netty.util.internal.SocketUtils.accept(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(NioServerSocketChannel.java:141) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:75) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,739][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][1] failed to rollback writer on close
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:215) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:234) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:429) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.rollbackInternalNoCommit(IndexWriter.java:2249) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.rollbackInternal(IndexWriter.java:2193) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.rollback(IndexWriter.java:2186) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.closeNoLock(InternalEngine.java:1342) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.Engine.failEngine(Engine.java:805) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:915) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,745][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][1] failed engine [refresh failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_5.cfs: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundReader.<init>(Lucene50CompoundReader.java:78) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.getCompoundReader(Lucene50CompoundFormat.java:71) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:74) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream$SegmentState.<init>(BufferedUpdatesStream.java:384) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.openSegmentStates(BufferedUpdatesStream.java:416) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:261) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.applyAllDeletesAndUpdates(IndexWriter.java:3456) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:3442) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:461) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,765][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][1]] marking and sending shard failed due to [shard failure, reason [refresh failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_5.cfs: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundReader.<init>(Lucene50CompoundReader.java:78) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.getCompoundReader(Lucene50CompoundFormat.java:71) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:74) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream$SegmentState.<init>(BufferedUpdatesStream.java:384) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.openSegmentStates(BufferedUpdatesStream.java:416) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:261) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.applyAllDeletesAndUpdates(IndexWriter.java:3456) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:3442) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:461) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,774][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [shard failure, reason [refresh failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_5.cfs: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_5.cfs: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundReader.<init>(Lucene50CompoundReader.java:78) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.getCompoundReader(Lucene50CompoundFormat.java:71) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:74) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream$SegmentState.<init>(BufferedUpdatesStream.java:384) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.openSegmentStates(BufferedUpdatesStream.java:416) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:261) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.applyAllDeletesAndUpdates(IndexWriter.java:3456) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:3442) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:461) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,801][INFO ][o.e.c.r.a.AllocationService] [WuuaeiX] Cluster health status changed from [YELLOW] to [RED] (reason: [shards failed [[locations][1]] ...]).
[2017-11-26T16:06:28,764][WARN ][o.e.i.IndexService       ] [WuuaeiX] [locations] failed to run task refresh - suppressing re-occurring exceptions unless the exception changes
org.elasticsearch.index.engine.RefreshFailedEngineException: Refresh failed
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:919) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_5.cfs: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundReader.<init>(Lucene50CompoundReader.java:78) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.getCompoundReader(Lucene50CompoundFormat.java:71) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentCoreReaders.<init>(SegmentCoreReaders.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentReader.<init>(SegmentReader.java:74) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream$SegmentState.<init>(BufferedUpdatesStream.java:384) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.openSegmentStates(BufferedUpdatesStream.java:416) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:261) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.applyAllDeletesAndUpdates(IndexWriter.java:3456) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:3442) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:461) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 9 more
[2017-11-26T16:06:28,806][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:28,811][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:29,051][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][1]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/translog/translog.ckp: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_112]
	at java.nio.file.Files.newByteChannel(Files.java:407) ~[?:1.8.0_112]
	at org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.translog.Checkpoint.read(Checkpoint.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.translog.Translog.readCheckpoint(Translog.java:1357) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.translog.Translog.<init>(Translog.java:161) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.openTranslog(InternalEngine.java:272) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:160) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:29,056][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [failed recovery], failure [RecoveryFailedException[[locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}]; nested: IndexShardRecoveryException[failed to recover from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/translog/translog.ckp: Too many open files in system]; ]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/translog/translog.ckp: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_112]
	at java.nio.file.Files.newByteChannel(Files.java:407) ~[?:1.8.0_112]
	at org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.translog.Checkpoint.read(Checkpoint.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.translog.Translog.readCheckpoint(Translog.java:1357) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.translog.Translog.<init>(Translog.java:161) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.openTranslog(InternalEngine.java:272) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:160) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:29,063][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:29,493][WARN ][i.n.c.DefaultChannelPipeline] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) ~[?:?]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:110) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_112]
	at io.netty.util.internal.SocketUtils.accept(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(NioServerSocketChannel.java:141) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:75) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:29,605][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][1]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:215) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:234) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:831) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:29,609][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [failed recovery], failure [RecoveryFailedException[[locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}]; nested: IndexShardRecoveryException[failed to recover from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system]; ]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:215) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:234) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:831) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:29,811][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][2] failed engine [refresh failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,317][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,317][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][2]] marking and sending shard failed due to [shard failure, reason [refresh failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,329][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][2] received shard failed for shard id [[locations][2]], allocation id [y8hEp6QlSb2ri1r2bZVnGA], primary term [0], message [shard failure, reason [refresh failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_5.nvd: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,333][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][1]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:215) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:234) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:831) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:30,346][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [failed recovery], failure [RecoveryFailedException[[locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}]; nested: IndexShardRecoveryException[failed to recover from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system]; ]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][1]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:215) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.listAll(FSDirectory.java:234) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.listAll(FilterDirectory.java:57) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:831) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:30,352][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300} has not removed previously failed shard. resending shard failure]
[2017-11-26T16:06:30,353][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,364][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,373][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,376][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,374][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,381][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,383][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,385][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,385][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,388][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,392][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,395][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,398][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,399][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,418][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,422][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,429][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,433][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,433][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,436][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,440][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,443][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,447][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,447][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,500][WARN ][i.n.c.DefaultChannelPipeline] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) ~[?:?]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:110) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_112]
	at io.netty.util.internal.SocketUtils.accept(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(NioServerSocketChannel.java:141) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:75) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,464][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,539][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,542][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,547][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,555][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,580][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,591][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,601][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,603][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,604][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,613][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,630][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,635][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,639][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,640][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,643][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,646][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,648][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,651][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,650][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,654][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,658][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,661][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,671][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,673][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,675][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,678][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,680][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,682][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,683][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,685][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,688][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,690][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,692][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,693][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,696][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,699][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,701][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,704][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,703][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,706][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,716][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,720][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,723][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,722][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,725][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,729][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,731][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,733][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,733][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,736][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,739][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,740][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,743][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,744][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,747][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,750][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,764][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,769][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,768][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,782][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,787][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,789][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,794][WARN ][o.e.g.GatewayAllocator$InternalPrimaryShardAllocator] [WuuaeiX] [locations][1]: failed to list shard for shard_started on node [WuuaeiX1RimIKqB0gbnf_A]
org.elasticsearch.action.FailedNodeException: Failed node [WuuaeiX1RimIKqB0gbnf_A]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.onFailure(TransportNodesAction.java:239) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction.access$200(TransportNodesAction.java:153) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$AsyncAction$1.handleException(TransportNodesAction.java:211) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1067) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1171) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1149) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.onFailure(TransportService.java:655) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:623) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.transport.RemoteTransportException: [WuuaeiX][127.0.0.1:9300][internal:gateway/local/started_shards[n]]
Caused by: org.elasticsearch.ElasticsearchException: failed to load started shards
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:171) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:275) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:119) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.TransportNodesListGatewayStartedShards.nodeOperation(TransportNodesListGatewayStartedShards.java:61) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction.nodeOperation(TransportNodesAction.java:140) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:262) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.action.support.nodes.TransportNodesAction$NodeTransportHandler.messageReceived(TransportNodesAction.java:258) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.transport.TransportService$7.doRun(TransportService.java:644) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 3 more
[2017-11-26T16:06:30,799][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,810][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,857][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][3] failed engine [refresh failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/3/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,860][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][3]] marking and sending shard failed due to [shard failure, reason [refresh failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/3/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,864][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][3] received shard failed for shard id [[locations][3]], allocation id [OClEMbkyTOuLEEa9Qv-O6g], primary term [0], message [shard failure, reason [refresh failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/3/index/_5.nvd: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/3/index/_5.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,879][WARN ][o.e.g.MetaStateService   ] [WuuaeiX] [[locations/C_vQZz9gTLa6yUoQKxJxKw]]: failed to write index state
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/_state: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:525) ~[?:1.8.0_112]
	at org.elasticsearch.gateway.MetaDataStateFormat.findMaxStateId(MetaDataStateFormat.java:241) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.write(MetaDataStateFormat.java:114) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.writeIndex(MetaStateService.java:132) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.GatewayMetaState.applyClusterState(GatewayMetaState.java:179) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.Gateway.applyClusterState(Gateway.java:183) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:30,882][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,114][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][1] failed engine [lucene commit failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_0.dii: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene60.Lucene60PointsWriter.finish(Lucene60PointsWriter.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writePoints(DefaultIndexingChain.java:223) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:148) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,117][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][1]] marking and sending shard failed due to [shard failure, reason [lucene commit failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_0.dii: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene60.Lucene60PointsWriter.finish(Lucene60PointsWriter.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writePoints(DefaultIndexingChain.java:223) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:148) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,118][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][1] tried to fail engine but engine is already failed. ignoring. [failed to recover from translog]
org.elasticsearch.index.engine.FlushFailedEngineException: Flush failed
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1069) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_0.dii: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene60.Lucene60PointsWriter.finish(Lucene60PointsWriter.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writePoints(DefaultIndexingChain.java:223) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:148) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 15 more
[2017-11-26T16:06:31,120][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][1] received shard failed for shard id [[locations][1]], allocation id [1LISHcczSrusUEa0RCPn0Q], primary term [0], message [shard failure, reason [lucene commit failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_0.dii: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/1/index/_0.dii: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene60.Lucene60PointsWriter.finish(Lucene60PointsWriter.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writePoints(DefaultIndexingChain.java:223) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:148) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,183][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][2] failed engine [lucene commit failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,188][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][2] tried to fail engine but engine is already failed. ignoring. [failed to recover from translog]
org.elasticsearch.index.engine.FlushFailedEngineException: Flush failed
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1069) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 15 more
[2017-11-26T16:06:31,308][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][2]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][2]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.FlushFailedEngineException: Flush failed
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1069) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:31,350][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][2] received shard failed for shard id [[locations][2]], allocation id [y8hEp6QlSb2ri1r2bZVnGA], primary term [0], message [failed recovery], failure [RecoveryFailedException[[locations][2]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}]; nested: IndexShardRecoveryException[failed to recover from gateway]; nested: FlushFailedEngineException[Flush failed]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system]; ]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][2]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.FlushFailedEngineException: Flush failed
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1069) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:31,415][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][2]] marking and sending shard failed due to [shard failure, reason [lucene commit failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,424][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][2] received shard failed for shard id [[locations][2]], allocation id [y8hEp6QlSb2ri1r2bZVnGA], primary term [0], message [shard failure, reason [lucene commit failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/2/index/_6.fnm: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene50.Lucene50CompoundFormat.write(Lucene50CompoundFormat.java:93) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4945) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:529) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:481) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:3009) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:3244) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:3207) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.commitIndexWriter(InternalEngine.java:1576) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.flush(InternalEngine.java:1062) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:253) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:221) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.recoverFromTranslog(InternalEngine.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1033) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,435][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][2] received shard failed for shard id [[locations][2]], allocation id [y8hEp6QlSb2ri1r2bZVnGA], primary term [0], message [master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300} has not removed previously failed shard. resending shard failure]
[2017-11-26T16:06:31,446][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][2] received shard failed for shard id [[locations][2]], allocation id [y8hEp6QlSb2ri1r2bZVnGA], primary term [0], message [master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300} has not removed previously failed shard. resending shard failure]
[2017-11-26T16:06:31,507][WARN ][i.n.c.DefaultChannelPipeline] An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.io.IOException: Too many open files in system
	at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:422) ~[?:?]
	at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:250) ~[?:?]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:110) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.internal.SocketUtils$5.run(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_112]
	at io.netty.util.internal.SocketUtils.accept(SocketUtils.java:107) ~[netty-common-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.socket.nio.NioServerSocketChannel.doReadMessages(NioServerSocketChannel.java:141) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.AbstractNioMessageChannel$NioMessageUnsafe.read(AbstractNioMessageChannel.java:75) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,935][WARN ][o.e.i.e.Engine           ] [WuuaeiX] [locations][4] failed engine [refresh failed]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/_8.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,939][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][4]] marking and sending shard failed due to [shard failure, reason [refresh failed]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/_8.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,950][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][4] received shard failed for shard id [[locations][4]], allocation id [QZSC6KJJQAC-IeBNcJusjg], primary term [0], message [shard failure, reason [refresh failed]], failure [FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/_8.nvd: Too many open files in system]]
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/_8.nvd: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.spi.FileSystemProvider.newOutputStream(FileSystemProvider.java:434) ~[?:1.8.0_112]
	at java.nio.file.Files.newOutputStream(Files.java:216) ~[?:1.8.0_112]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:413) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory$FSIndexOutput.<init>(FSDirectory.java:409) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FSDirectory.createOutput(FSDirectory.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.RateLimitedFSDirectory.createOutput(RateLimitedFSDirectory.java:40) ~[elasticsearch-5.6.3.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.createOutput(FilterDirectory.java:73) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsConsumer.<init>(Lucene53NormsConsumer.java:43) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsConsumer(Lucene53NormsFormat.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.writeNorms(DefaultIndexingChain.java:299) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DefaultIndexingChain.flush(DefaultIndexingChain.java:136) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:444) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:539) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:653) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:445) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:291) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:266) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:256) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.FilterDirectoryReader.doOpenIfChanged(FilterDirectoryReader.java:104) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:140) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:156) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.search.ReferenceManager.maybeRefreshBlocking(ReferenceManager.java:253) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.refresh(InternalEngine.java:909) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.refresh(IndexShard.java:632) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.maybeRefreshEngine(IndexService.java:690) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.access$400(IndexService.java:92) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$AsyncRefreshTask.runInternal(IndexService.java:832) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService$BaseAsyncTask.run(IndexService.java:743) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:31,957][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][4] received shard failed for shard id [[locations][4]], allocation id [QZSC6KJJQAC-IeBNcJusjg], primary term [0], message [master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300} has not removed previously failed shard. resending shard failure]
[2017-11-26T16:06:31,987][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][4]] marking and sending shard failed due to [failed to create shard]
org.elasticsearch.ElasticsearchException: java.io.IOException: failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]
	at org.elasticsearch.ExceptionsHelper.maybeThrowRuntimeAndSuppress(ExceptionsHelper.java:150) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:334) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.ShardPath.loadShardPath(ShardPath.java:118) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.createShard(IndexService.java:298) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:499) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:147) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.createShard(IndicesClusterStateService.java:542) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.createOrUpdateShards(IndicesClusterStateService.java:519) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:204) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.io.IOException: failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:327) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 19 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_112]
	at java.nio.file.Files.newByteChannel(Files.java:407) ~[?:1.8.0_112]
	at org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.gateway.MetaDataStateFormat.read(MetaDataStateFormat.java:187) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:322) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 19 more
[2017-11-26T16:06:31,990][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][4] received shard failed for shard id [[locations][4]], allocation id [QZSC6KJJQAC-IeBNcJusjg], primary term [0], message [failed to create shard], failure [ElasticsearchException[java.io.IOException: failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]]; nested: IOException[failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st: Too many open files in system]; ]
org.elasticsearch.ElasticsearchException: java.io.IOException: failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]
	at org.elasticsearch.ExceptionsHelper.maybeThrowRuntimeAndSuppress(ExceptionsHelper.java:150) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:334) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.ShardPath.loadShardPath(ShardPath.java:118) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.IndexService.createShard(IndexService.java:298) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:499) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.IndicesService.createShard(IndicesService.java:147) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.createShard(IndicesClusterStateService.java:542) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.createOrUpdateShards(IndicesClusterStateService.java:519) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.indices.cluster.IndicesClusterStateService.applyClusterState(IndicesClusterStateService.java:204) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.callClusterStateAppliers(ClusterService.java:814) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:768) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.io.IOException: failed to read [id:0, legacy:false, file:/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:327) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 19 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/_state/state-0.st: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214) ~[?:?]
	at java.nio.file.Files.newByteChannel(Files.java:361) ~[?:1.8.0_112]
	at java.nio.file.Files.newByteChannel(Files.java:407) ~[?:1.8.0_112]
	at org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:77) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.gateway.MetaDataStateFormat.read(MetaDataStateFormat.java:187) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaDataStateFormat.loadLatestState(MetaDataStateFormat.java:322) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 19 more
[2017-11-26T16:06:32,047][WARN ][o.e.i.c.IndicesClusterStateService] [WuuaeiX] [[locations][4]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][4]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/segments_1: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentInfos.readCommit(SegmentInfos.java:286) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexFileDeleter.<init>(IndexFileDeleter.java:165) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:974) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:32,051][WARN ][o.e.c.a.s.ShardStateAction] [WuuaeiX] [locations][4] received shard failed for shard id [[locations][4]], allocation id [QZSC6KJJQAC-IeBNcJusjg], primary term [0], message [failed recovery], failure [RecoveryFailedException[[locations][4]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}]; nested: IndexShardRecoveryException[failed to recover from gateway]; nested: EngineCreationFailureException[failed to create engine]; nested: FileSystemException[/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/segments_1: Too many open files in system]; ]
org.elasticsearch.indices.recovery.RecoveryFailedException: [locations][4]: Recovery failed on {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{VvQOprsHSeiHKje9Wb8rcA}{127.0.0.1}{127.0.0.1:9300}
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1488) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: org.elasticsearch.index.shard.IndexShardRecoveryException: failed to recover from gateway
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:365) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: org.elasticsearch.index.engine.EngineCreationFailureException: failed to create engine
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:163) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
Caused by: java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices/C_vQZz9gTLa6yUoQKxJxKw/4/index/segments_1: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177) ~[?:?]
	at java.nio.channels.FileChannel.open(FileChannel.java:287) ~[?:1.8.0_112]
	at java.nio.channels.FileChannel.open(FileChannel.java:335) ~[?:1.8.0_112]
	at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:238) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:99) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:137) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.SegmentInfos.readCommit(SegmentInfos.java:286) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexFileDeleter.<init>(IndexFileDeleter.java:165) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.apache.lucene.index.IndexWriter.<init>(IndexWriter.java:974) ~[lucene-core-6.6.1.jar:6.6.1 9aa465a89b64ff2dabe7b4d50c472de32c298683 - varunthacker - 2017-08-29 21:54:39]
	at org.elasticsearch.index.engine.InternalEngine.createWriter(InternalEngine.java:1405) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngine.<init>(InternalEngine.java:157) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.engine.InternalEngineFactory.newReadWriteEngine(InternalEngineFactory.java:25) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.newEngine(IndexShard.java:1602) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.createNewEngine(IndexShard.java:1584) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.internalPerformTranslogRecovery(IndexShard.java:1027) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.performTranslogRecovery(IndexShard.java:987) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.internalRecoverFromStore(StoreRecovery.java:360) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.lambda$recoverFromStore$0(StoreRecovery.java:90) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.executeRecovery(StoreRecovery.java:257) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.StoreRecovery.recoverFromStore(StoreRecovery.java:88) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.recoverFromStore(IndexShard.java:1236) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.index.shard.IndexShard.lambda$startRecovery$1(IndexShard.java:1484) ~[elasticsearch-5.6.3.jar:5.6.3]
	... 4 more
[2017-11-26T16:06:32,058][WARN ][o.e.g.DanglingIndicesState] [WuuaeiX] failed to list dangling indices
java.nio.file.FileSystemException: /Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0/indices: Too many open files in system
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102) ~[?:?]
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107) ~[?:?]
	at sun.nio.fs.UnixFileSystemProvider.newDirectoryStream(UnixFileSystemProvider.java:407) ~[?:?]
	at java.nio.file.Files.newDirectoryStream(Files.java:457) ~[?:1.8.0_112]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFoldersForPath(NodeEnvironment.java:844) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.env.NodeEnvironment.availableIndexFolders(NodeEnvironment.java:823) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.MetaStateService.loadIndicesStates(MetaStateService.java:89) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewDanglingIndices(DanglingIndicesState.java:131) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.findNewAndAddDanglingIndices(DanglingIndicesState.java:116) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.processDanglingIndices(DanglingIndicesState.java:81) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.gateway.DanglingIndicesState.clusterChanged(DanglingIndicesState.java:185) ~[elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.lambda$publishAndApplyChanges$7(ClusterService.java:777) ~[elasticsearch-5.6.3.jar:5.6.3]
	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948) [?:1.8.0_112]
	at java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:742) [?:1.8.0_112]
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) [?:1.8.0_112]
	at org.elasticsearch.cluster.service.ClusterService.publishAndApplyChanges(ClusterService.java:774) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService.runTasks(ClusterService.java:587) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.ClusterService$ClusterServiceTaskBatcher.run(ClusterService.java:263) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:247) [elasticsearch-5.6.3.jar:5.6.3]
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:210) [elasticsearch-5.6.3.jar:5.6.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
[2017-11-26T16:06:39,425][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 10.8gb[4.6%], shards will be relocated away from this node
[2017-11-26T16:06:39,425][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:07:09,440][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T16:07:39,448][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.9%], shards will be relocated away from this node
[2017-11-26T16:07:39,448][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:08:09,461][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:08:39,554][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:08:39,560][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:08:39,482][WARN ][o.e.t.n.Netty4Transport  ] [WuuaeiX] write and flush on the network layer failed (channel: [id: 0x94b520a8, L:0.0.0.0/0.0.0.0:9300 ! R:/127.0.0.1:54189])
java.nio.channels.ClosedChannelException: null
	at io.netty.channel.AbstractChannel$AbstractUnsafe.write(...)(Unknown Source) ~[?:?]
[2017-11-26T16:09:09,582][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:09:39,595][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:09:39,597][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:10:09,605][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.4gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:10:18,558][INFO ][o.e.n.Node               ] [WuuaeiX] stopping ...
[2017-11-26T16:16:15,837][INFO ][o.e.n.Node               ] [] initializing ...
[2017-11-26T16:16:15,966][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] using [1] data paths, mounts [[/ (/dev/disk1s1)]], net usable_space [11.4gb], net total_space [233.5gb], spins? [unknown], types [apfs]
[2017-11-26T16:16:15,967][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] heap size [1.7gb], compressed ordinary object pointers [true]
[2017-11-26T16:16:15,987][INFO ][o.e.n.Node               ] node name [WuuaeiX] derived from node ID [WuuaeiX1RimIKqB0gbnf_A]; set [node.name] to override
[2017-11-26T16:16:15,988][INFO ][o.e.n.Node               ] version[5.6.3], pid[6336], build[1a2f265/2017-10-06T20:33:39.012Z], OS[Mac OS X/10.13.1/x86_64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_112/25.112-b16]
[2017-11-26T16:16:15,988][INFO ][o.e.n.Node               ] JVM arguments [-Des.path.home=/Users/Guida/GitHub/lime/backend/elastic-search]
[2017-11-26T16:16:19,111][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [aggs-matrix-stats]
[2017-11-26T16:16:19,111][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [ingest-common]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-expression]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-groovy]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-mustache]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-painless]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [parent-join]
[2017-11-26T16:16:19,112][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [percolator]
[2017-11-26T16:16:19,113][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [reindex]
[2017-11-26T16:16:19,113][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty3]
[2017-11-26T16:16:19,113][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty4]
[2017-11-26T16:16:19,114][INFO ][o.e.p.PluginsService     ] [WuuaeiX] no plugins loaded
[2017-11-26T16:16:21,814][INFO ][o.e.d.DiscoveryModule    ] [WuuaeiX] using discovery type [zen]
[2017-11-26T16:16:22,784][INFO ][o.e.n.Node               ] initialized
[2017-11-26T16:16:22,785][INFO ][o.e.n.Node               ] [WuuaeiX] starting ...
[2017-11-26T16:16:22,869][INFO ][i.n.u.i.PlatformDependent] Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system instability.
[2017-11-26T16:16:23,094][INFO ][o.e.t.TransportService   ] [WuuaeiX] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2017-11-26T16:16:23,110][WARN ][o.e.b.BootstrapChecks    ] [WuuaeiX] initial heap size [134217728] not equal to maximum heap size [2147483648]; this can cause resize pauses and prevents mlockall from locking the entire heap
[2017-11-26T16:16:26,177][INFO ][o.e.c.s.ClusterService   ] [WuuaeiX] new_master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{PQ8tlcTLRle4AfJygclM6A}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2017-11-26T16:16:26,207][INFO ][o.e.h.n.Netty4HttpServerTransport] [WuuaeiX] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2017-11-26T16:16:26,208][INFO ][o.e.n.Node               ] [WuuaeiX] started
[2017-11-26T16:16:26,443][INFO ][o.e.g.GatewayService     ] [WuuaeiX] recovered [1] indices into cluster_state
[2017-11-26T16:16:27,380][INFO ][o.e.c.r.a.AllocationService] [WuuaeiX] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[locations][0]] ...]).
[2017-11-26T16:16:56,210][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:16:56,211][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:17:26,237][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:17:29,978][WARN ][o.e.m.j.JvmGcMonitorService] [WuuaeiX] [gc][67] overhead, spent [536ms] collecting in the last [1s]
[2017-11-26T16:17:56,255][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.3gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:17:56,256][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:18:26,275][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:18:56,310][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:18:56,312][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:19:26,333][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:19:56,351][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:19:56,352][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:20:26,372][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:20:56,392][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:20:56,393][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:21:26,412][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:21:56,434][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:21:56,434][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:22:26,451][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:22:56,471][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:22:56,471][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:23:26,486][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:23:56,506][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:23:56,506][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:24:26,522][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:24:56,539][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:24:56,540][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:25:26,556][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:25:56,567][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:25:56,568][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:26:26,582][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:26:56,626][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:26:56,626][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:27:26,641][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:27:56,660][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:27:56,660][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:28:26,678][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:28:56,694][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:28:56,695][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:29:26,716][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:29:56,739][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:29:56,740][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:30:26,756][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:30:56,773][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:30:56,774][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:31:26,790][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:31:56,807][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:31:56,809][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:32:26,826][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:32:56,841][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:32:56,841][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:33:26,873][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:33:56,890][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:33:56,891][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:34:26,905][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:34:56,942][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:34:56,943][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:35:26,958][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:35:56,970][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:35:56,971][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:36:26,987][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:36:57,039][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:36:57,040][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:37:27,060][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:37:57,071][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:37:57,072][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:38:27,091][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:38:57,108][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:38:57,109][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:39:27,122][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:39:57,142][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:39:57,142][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:40:27,157][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:40:57,175][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.8%], shards will be relocated away from this node
[2017-11-26T16:40:57,175][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:41:27,193][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:41:57,208][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:41:57,208][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:42:27,224][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:42:57,237][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:42:57,237][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:43:27,251][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:43:57,268][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:43:57,268][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:44:27,282][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:44:57,298][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:44:57,299][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:45:27,315][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:45:57,335][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 11.2gb[4.7%], shards will be relocated away from this node
[2017-11-26T16:45:57,335][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T16:46:02,990][INFO ][o.e.n.Node               ] [WuuaeiX] stopping ...
[2017-11-26T20:01:49,618][INFO ][o.e.n.Node               ] [] initializing ...
[2017-11-26T20:01:49,748][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] using [1] data paths, mounts [[/ (/dev/disk1s1)]], net usable_space [8.6gb], net total_space [233.5gb], spins? [unknown], types [apfs]
[2017-11-26T20:01:49,749][INFO ][o.e.e.NodeEnvironment    ] [WuuaeiX] heap size [1.7gb], compressed ordinary object pointers [true]
[2017-11-26T20:01:49,778][INFO ][o.e.n.Node               ] node name [WuuaeiX] derived from node ID [WuuaeiX1RimIKqB0gbnf_A]; set [node.name] to override
[2017-11-26T20:01:49,779][INFO ][o.e.n.Node               ] version[5.6.3], pid[11632], build[1a2f265/2017-10-06T20:33:39.012Z], OS[Mac OS X/10.13.1/x86_64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_112/25.112-b16]
[2017-11-26T20:01:49,779][INFO ][o.e.n.Node               ] JVM arguments [-Des.path.home=/Users/Guida/GitHub/lime/backend/elastic-search]
[2017-11-26T20:01:51,484][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [aggs-matrix-stats]
[2017-11-26T20:01:51,484][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [ingest-common]
[2017-11-26T20:01:51,484][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-expression]
[2017-11-26T20:01:51,485][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-groovy]
[2017-11-26T20:01:51,485][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-mustache]
[2017-11-26T20:01:51,485][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [lang-painless]
[2017-11-26T20:01:51,485][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [parent-join]
[2017-11-26T20:01:51,485][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [percolator]
[2017-11-26T20:01:51,486][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [reindex]
[2017-11-26T20:01:51,486][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty3]
[2017-11-26T20:01:51,486][INFO ][o.e.p.PluginsService     ] [WuuaeiX] loaded module [transport-netty4]
[2017-11-26T20:01:51,487][INFO ][o.e.p.PluginsService     ] [WuuaeiX] no plugins loaded
[2017-11-26T20:01:54,250][INFO ][o.e.d.DiscoveryModule    ] [WuuaeiX] using discovery type [zen]
[2017-11-26T20:01:55,269][INFO ][o.e.n.Node               ] initialized
[2017-11-26T20:01:55,270][INFO ][o.e.n.Node               ] [WuuaeiX] starting ...
[2017-11-26T20:01:55,333][INFO ][i.n.u.i.PlatformDependent] Your platform does not provide complete low-level API for accessing direct buffers reliably. Unless explicitly requested, heap buffer will always be preferred to avoid potential system instability.
[2017-11-26T20:01:55,570][INFO ][o.e.t.TransportService   ] [WuuaeiX] publish_address {127.0.0.1:9300}, bound_addresses {[fe80::1]:9300}, {[::1]:9300}, {127.0.0.1:9300}
[2017-11-26T20:01:55,583][WARN ][o.e.b.BootstrapChecks    ] [WuuaeiX] initial heap size [134217728] not equal to maximum heap size [2147483648]; this can cause resize pauses and prevents mlockall from locking the entire heap
[2017-11-26T20:01:58,667][INFO ][o.e.c.s.ClusterService   ] [WuuaeiX] new_master {WuuaeiX}{WuuaeiX1RimIKqB0gbnf_A}{fRGYj10AQuyyYceHCmpPSQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-elected-as-master ([0] nodes joined)
[2017-11-26T20:01:58,702][INFO ][o.e.h.n.Netty4HttpServerTransport] [WuuaeiX] publish_address {127.0.0.1:9200}, bound_addresses {[fe80::1]:9200}, {[::1]:9200}, {127.0.0.1:9200}
[2017-11-26T20:01:58,702][INFO ][o.e.n.Node               ] [WuuaeiX] started
[2017-11-26T20:01:58,944][INFO ][o.e.g.GatewayService     ] [WuuaeiX] recovered [1] indices into cluster_state
[2017-11-26T20:01:59,858][INFO ][o.e.c.r.a.AllocationService] [WuuaeiX] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[locations][4]] ...]).
[2017-11-26T20:02:28,737][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:02:28,739][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:02:58,789][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:03:28,810][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:03:28,811][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:03:58,836][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:04:28,856][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:04:28,857][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:04:58,880][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:05:28,902][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:05:28,903][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:05:39,392][WARN ][o.e.m.j.JvmGcMonitorService] [WuuaeiX] [gc][223] overhead, spent [931ms] collecting in the last [1.3s]
[2017-11-26T20:05:58,923][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:06:29,010][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:06:29,011][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:06:59,032][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:07:29,060][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:07:29,060][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:07:59,087][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:08:29,124][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:08:29,125][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:08:59,191][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:09:29,232][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:09:29,234][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:09:59,260][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:10:29,280][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:10:29,281][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:10:59,334][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:11:29,353][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:11:29,353][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:11:59,402][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:12:29,426][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:12:29,426][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:12:59,449][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:13:29,474][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.6gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:13:29,474][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:13:59,494][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:14:29,553][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
[2017-11-26T20:14:29,554][INFO ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] rerouting shards: [high disk watermark exceeded on one or more nodes]
[2017-11-26T20:14:59,586][WARN ][o.e.c.r.a.DiskThresholdMonitor] [WuuaeiX] high disk watermark [90%] exceeded on [WuuaeiX1RimIKqB0gbnf_A][WuuaeiX][/Users/Guida/GitHub/lime/backend/elastic-search/data/nodes/0] free: 8.5gb[3.6%], shards will be relocated away from this node
